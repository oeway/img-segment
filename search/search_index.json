{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Deep learning with ImJoy \u00b6 We provide Python libraries powered by ImJoy to perform cell segmentation. ImJoy \u00b6 ImJoy is image processing platform with an easy to use interface powered by a Python engine running in the background. ImJoy plays a central role in most analysis workflows. We provide links to install the different ImJoy plugins in dedicated ImJoy workspaces. Once installed, ImJoy remembers the workspaces and plugins and you simply have to open the web app and select the appropriate workspace https://imjoy.io/#/app If you press on the installation link, the ImJoy web app will open and display a dialog asking if you want to install the specified plugin. To confirm, press the install button. Plugins require the ImJoy Plugin Engine , to perform computations in Python. You will need to install it only once, but launch it each time you work with ImJoy. For more information for how to install and use the pluging engine, please consult the ImJoy documentation . Segmentation with deep learning \u00b6 We use deep learning to perform cell segmentation. This requires a training step in order for the model to learn how to segment the data. Once a model is it training it can be applied on new data. We provide pre-trained models. While these model might already perform relatively well on your data, re-training them might further improve their performance. Training \u00b6 In order to train a model images have to be annotated, e.g. the biological structures of interest highlighted in the image. These annotated images can then be used for training. Prediction \u00b6 Once a model is trained, you can apply it on new data.","title":"Summary"},{"location":"#deep-learning-with-imjoy","text":"We provide Python libraries powered by ImJoy to perform cell segmentation.","title":"Deep learning with ImJoy"},{"location":"#imjoy","text":"ImJoy is image processing platform with an easy to use interface powered by a Python engine running in the background. ImJoy plays a central role in most analysis workflows. We provide links to install the different ImJoy plugins in dedicated ImJoy workspaces. Once installed, ImJoy remembers the workspaces and plugins and you simply have to open the web app and select the appropriate workspace https://imjoy.io/#/app If you press on the installation link, the ImJoy web app will open and display a dialog asking if you want to install the specified plugin. To confirm, press the install button. Plugins require the ImJoy Plugin Engine , to perform computations in Python. You will need to install it only once, but launch it each time you work with ImJoy. For more information for how to install and use the pluging engine, please consult the ImJoy documentation .","title":"ImJoy"},{"location":"#segmentation-with-deep-learning","text":"We use deep learning to perform cell segmentation. This requires a training step in order for the model to learn how to segment the data. Once a model is it training it can be applied on new data. We provide pre-trained models. While these model might already perform relatively well on your data, re-training them might further improve their performance.","title":"Segmentation with deep learning"},{"location":"#training","text":"In order to train a model images have to be annotated, e.g. the biological structures of interest highlighted in the image. These annotated images can then be used for training.","title":"Training"},{"location":"#prediction","text":"Once a model is trained, you can apply it on new data.","title":"Prediction"},{"location":"annotation/","text":"Image annotation \u00b6 Annotations are necessary to provide a ground truth for the neural network during training. In this step, the structures of interest, e.g. cell and nuclei, are outline in the images to generate data that will be used to train the neural network. For the moment, we support annotations Annotations performed in ImJoy. These annotations can be stored in the GeoJson format. Annotations from FIJI . Using annotations in other formats is in principle possible but will require the implementation of dedicated wrappers. Annotations in ImJoy \u00b6 ImJoy provides a dedicated plugin to perform annotations Annotations with FIJI \u00b6 FIJI allows to annotate images, and save the annotations into a separate file. Open FIJI Open the ROI manager : Analyze > Tools > ROI manager Open image that you will annotate. Select the annotation tool of choice, e.g. freehand or polygon. Outline first structure of interest. When done, press Add(t) in ROI manager to add outline. Proceed with all other structures. Enabling \"Show all\", will show all defined regions. Save regions by highlighting all regions in the list and pressing on More > Save ... If only one region is saved, this will created a file with the extension .roi . If multiple annotations are saved this will create a .zip file. As a file-name choose the name of the annotated image, followed by a suffix such as _RoiSet.zip . If you have different structures (e.g. nuclei and cells), choose the suffix accordingly, e.g. _cells_RoiSet.zip and _nuclei_RoiSet.zip . IMPORTANT : all structures, e.g. nuclei, have to be annotated. Unwanted elements, e.g. nuclei touching the cell border, can be removed in a post-processing step. Convert annotations to images with masks \u00b6 Once you have annotated the images, you have to convert these annotations to images which can be used as an input for the neural network. We provide a dedicated ImJoy plugin to perform this task. This plugin has different tags , which render the plugin for a given segmentation tasks. You only have to specify a few key properties of your data. The screenshot shown below shows the plugin interface for the segmentation of the cell membrane in the example data. Note that here is only one channel. For the example above, you have to specify Unique identifier for each channel (here there is only one channel with the identifier C3- ) File extension of your images ( .tif in this case) File extension of the annotations (FIJI annotations with _RoiSet.zip ) Once you specified these parameters you can convert an entire folder with annotations by pressing on the plugin itself (the blue text AnnotationImporter ). You will be asked to specify the parent folder containing the different data-sets. The plugin will open all annotation files, create the necessary mask images, and save them together with the corresponding images in a new folder unet_data in the processed folder. It contains two subfolders train and valid . Here, a dedicated folder with the name of the image is created. The actual images are then named with the channel identifier (e.g. cells ) and the image masks with the channel identifier followed by the mask type (e.g. cell_mask_edge.png ). . \u251c\u2500 anet/ \u2502 \u251c\u2500 train/ \u2502 \u2502 \u251c\u2500 C3-img4 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img5 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u2502 \u251c\u2500 valid/ \u2502 \u2502 \u251c\u2500 C3-img1 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img2 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u251c\u2500 test/ \u2502 ... \u251c\u2500 train/ \u2502 ... \u251c\u2500 valid/ \u2502 ... This directory can be used as an input directory for the training. NEEDED? It will also create a .zip file that can be easily distributed. Defining a root folder \u00b6 By default, ImJoy will open files in your home folder. If your data is at a different location, you can set a root folder. Each time you specify a file, ImJoy will open the file-dialog in this root folder. Press the button Root folder and specify the desired folder. The specified root folder is also saved, and will be resused the next time you launch ImJoy.","title":"Annotations"},{"location":"annotation/#image-annotation","text":"Annotations are necessary to provide a ground truth for the neural network during training. In this step, the structures of interest, e.g. cell and nuclei, are outline in the images to generate data that will be used to train the neural network. For the moment, we support annotations Annotations performed in ImJoy. These annotations can be stored in the GeoJson format. Annotations from FIJI . Using annotations in other formats is in principle possible but will require the implementation of dedicated wrappers.","title":"Image annotation"},{"location":"annotation/#annotations-in-imjoy","text":"ImJoy provides a dedicated plugin to perform annotations","title":"Annotations in ImJoy"},{"location":"annotation/#annotations-with-fiji","text":"FIJI allows to annotate images, and save the annotations into a separate file. Open FIJI Open the ROI manager : Analyze > Tools > ROI manager Open image that you will annotate. Select the annotation tool of choice, e.g. freehand or polygon. Outline first structure of interest. When done, press Add(t) in ROI manager to add outline. Proceed with all other structures. Enabling \"Show all\", will show all defined regions. Save regions by highlighting all regions in the list and pressing on More > Save ... If only one region is saved, this will created a file with the extension .roi . If multiple annotations are saved this will create a .zip file. As a file-name choose the name of the annotated image, followed by a suffix such as _RoiSet.zip . If you have different structures (e.g. nuclei and cells), choose the suffix accordingly, e.g. _cells_RoiSet.zip and _nuclei_RoiSet.zip . IMPORTANT : all structures, e.g. nuclei, have to be annotated. Unwanted elements, e.g. nuclei touching the cell border, can be removed in a post-processing step.","title":"Annotations with FIJI"},{"location":"annotation/#convert-annotations-to-images-with-masks","text":"Once you have annotated the images, you have to convert these annotations to images which can be used as an input for the neural network. We provide a dedicated ImJoy plugin to perform this task. This plugin has different tags , which render the plugin for a given segmentation tasks. You only have to specify a few key properties of your data. The screenshot shown below shows the plugin interface for the segmentation of the cell membrane in the example data. Note that here is only one channel. For the example above, you have to specify Unique identifier for each channel (here there is only one channel with the identifier C3- ) File extension of your images ( .tif in this case) File extension of the annotations (FIJI annotations with _RoiSet.zip ) Once you specified these parameters you can convert an entire folder with annotations by pressing on the plugin itself (the blue text AnnotationImporter ). You will be asked to specify the parent folder containing the different data-sets. The plugin will open all annotation files, create the necessary mask images, and save them together with the corresponding images in a new folder unet_data in the processed folder. It contains two subfolders train and valid . Here, a dedicated folder with the name of the image is created. The actual images are then named with the channel identifier (e.g. cells ) and the image masks with the channel identifier followed by the mask type (e.g. cell_mask_edge.png ). . \u251c\u2500 anet/ \u2502 \u251c\u2500 train/ \u2502 \u2502 \u251c\u2500 C3-img4 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img5 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u2502 \u251c\u2500 valid/ \u2502 \u2502 \u251c\u2500 C3-img1 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img2 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u251c\u2500 test/ \u2502 ... \u251c\u2500 train/ \u2502 ... \u251c\u2500 valid/ \u2502 ... This directory can be used as an input directory for the training. NEEDED? It will also create a .zip file that can be easily distributed.","title":"Convert annotations to images with masks"},{"location":"annotation/#defining-a-root-folder","text":"By default, ImJoy will open files in your home folder. If your data is at a different location, you can set a root folder. Each time you specify a file, ImJoy will open the file-dialog in this root folder. Press the button Root folder and specify the desired folder. The specified root folder is also saved, and will be resused the next time you launch ImJoy.","title":"Defining a root folder"},{"location":"cell-segmentation/","text":"Cell segmentation \u00b6 The A-net plugin predicts mask for the different fluorescent channels. This masks are essentially tresholded images. To obtain individual cells or nuclei, we provide a dedicate plugin to perform this step.","title":"Segmentation"},{"location":"cell-segmentation/#cell-segmentation","text":"The A-net plugin predicts mask for the different fluorescent channels. This masks are essentially tresholded images. To obtain individual cells or nuclei, we provide a dedicate plugin to perform this step.","title":"Cell segmentation"},{"location":"data-organization/","text":"Data organisation \u00b6 Here we describe how the data has to be organised to perform either prediction or training. Prediction \u00b6 Training \u00b6 Data has to be split into two folders train , valid , and test . The train folder will be used to train the neural network, the valid folder to continuously monitor how well the training worked. Both folders have to contain images and annotations. The test folder can then be used to test the trained network. It only needs to contain images that should be segmented. The example below show the folder structure with a few annotated images. . \u251c\u2500 test/ \u2502 \u251c\u2500 C1-img30.tif \u2502 \u251c\u2500 C1-img31.tif \u2502 ... \u251c\u2500 train/ \u2502 \u251c\u2500 C1-img4.tif \u2502 \u251c\u2500 C1-img4__RoiSet.zip \u2502 \u251c\u2500 C1-img5.tif \u2502 \u251c\u2500 C1-img5__RoiSet.zip \u2502 ... \u251c\u2500 valid/ \u2502 \u251c\u2500 C1-img1.tif \u2502 \u251c\u2500 C1-img1__RoiSet.zip \u2502 \u251c\u2500 C1-img2.tif \u2502 \u251c\u2500 C1-img2__RoiSet.zip . There is no simple rule for how many images / annotated cells or nuclei you will need to obtain good results. As an example, for standard segmentation of adherent cells, we obtained good results with a training set of 5 images (with up to 10-15 cells per image), and test set of 2 images. For more challenging data-sets, you can add more training data if you see that the performance is not satisfying with the current training data set.","title":"Data organization"},{"location":"data-organization/#data-organisation","text":"Here we describe how the data has to be organised to perform either prediction or training.","title":"Data organisation"},{"location":"data-organization/#prediction","text":"","title":"Prediction"},{"location":"data-organization/#training","text":"Data has to be split into two folders train , valid , and test . The train folder will be used to train the neural network, the valid folder to continuously monitor how well the training worked. Both folders have to contain images and annotations. The test folder can then be used to test the trained network. It only needs to contain images that should be segmented. The example below show the folder structure with a few annotated images. . \u251c\u2500 test/ \u2502 \u251c\u2500 C1-img30.tif \u2502 \u251c\u2500 C1-img31.tif \u2502 ... \u251c\u2500 train/ \u2502 \u251c\u2500 C1-img4.tif \u2502 \u251c\u2500 C1-img4__RoiSet.zip \u2502 \u251c\u2500 C1-img5.tif \u2502 \u251c\u2500 C1-img5__RoiSet.zip \u2502 ... \u251c\u2500 valid/ \u2502 \u251c\u2500 C1-img1.tif \u2502 \u251c\u2500 C1-img1__RoiSet.zip \u2502 \u251c\u2500 C1-img2.tif \u2502 \u251c\u2500 C1-img2__RoiSet.zip . There is no simple rule for how many images / annotated cells or nuclei you will need to obtain good results. As an example, for standard segmentation of adherent cells, we obtained good results with a training set of 5 images (with up to 10-15 cells per image), and test set of 2 images. For more challenging data-sets, you can add more training data if you see that the performance is not satisfying with the current training data set.","title":"Training"},{"location":"licence/","text":"License \u00b6 MIT License Copyright \u00a9 Wei Ouyang Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Licence"},{"location":"licence/#license","text":"MIT License Copyright \u00a9 Wei Ouyang Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"mask-generation/","text":"Image annotation \u00b6 In this step, the structures of interest, e.g. cell and nuclei, are outline in the images to generate data that will be used to train the neural network. For the moment, we support annotations f Annotations stored in GeoJson format. We provide a dedicated ImJoy plugin to generate these. Annotations from FIJI . Using annotations in other formats is in principle possible but will require the implementation of dedicated wrappers. Annotations in GeoJson with ImJoy \u00b6 ImJoy provides a dedicated plugin to perform annotations Annotations with FIJI \u00b6 FIJI allows to annotate images, and save the annotations into a separate file. Open FIJI Open the ROI manager : Analyze > Tools > ROI manager Open image that you will annotate. Select the annotation tool of choice, e.g. freehand or polygon. Outline first structure of interest. When done, press Add(t) in ROI manager to add outline. Proceed with all other structures. Enabling \"Show all\", will show all defined regions. Save regions by highlighting all regions in the list and pressing on More > Save ... If only one region is saved, this will created a file with the extension .roi . If multiple annotations are saved this will create a .zip file. As a file-name choose the name of the annotated image, followed by a suffix such as _RoiSet.zip . If you have different structures (e.g. nuclei and cells), choose the suffix accordingly, e.g. _cells_RoiSet.zip and _nuclei_RoiSet.zip . IMPORTANT : all structures, e.g. nuclei, have to be annotated. Unwanted elements, e.g. nuclei touching the cell border, can be removed in a post-processing step. Convert annotations to images \u00b6 Once you have annotated the images, you have to convert these annotations to images which can be used as an input for the A-net. We provide a dedicated ImJoy plugin to perform this task. This plugin has different tags , which render the plugin for a given segmentation tasks. You only have to specify a few key properties of your data. The screenshot shown below shows the plugin interface for the segmentation of the cell membrane in the example data. Note that here is only one channel. For the example above, you have to specify Unique identifier for each channel (here there is only one channel with the identifier C3- ) File extension of your images ( .tif in this case) File extension of the annotations (FIJI annotations with _RoiSet.zip ) Once you specified these parameters you can convert an entire folder with annotations by pressing on the plugin itself (the blue text AnnotationImporter ). You will be asked to specify the parent folder containing the different data-sets. The plugin will open all annotation files, create the necessary mask images, and save them together with the corresponding images in a new folder unet_data in the processed folder. It contains two subfolders train and valid . Here, a dedicated folder with the name of the image is created. The actual images are then named with the channel identifier (e.g. cells ) and the image masks with the channel identifier followed by the mask type (e.g. cell_mask_edge.png ). . \u251c\u2500 anet/ \u2502 \u251c\u2500 train/ \u2502 \u2502 \u251c\u2500 C3-img4 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img5 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u2502 \u251c\u2500 valid/ \u2502 \u2502 \u251c\u2500 C3-img1 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img2 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u251c\u2500 test/ \u2502 ... \u251c\u2500 train/ \u2502 ... \u251c\u2500 valid/ \u2502 ... This directory can be used as an input directory for the training. NEEDED? It will also create a .zip file that can be easily distributed. Defining a root folder \u00b6 By default, ImJoy will open files in your home folder. If your data is at a different location, you can set a root folder. Each time you specify a file, ImJoy will open the file-dialog in this root folder. Press the button Root folder and specify the desired folder. The specified root folder is also saved, and will be resused the next time you launch ImJoy.","title":"Image annotation"},{"location":"mask-generation/#image-annotation","text":"In this step, the structures of interest, e.g. cell and nuclei, are outline in the images to generate data that will be used to train the neural network. For the moment, we support annotations f Annotations stored in GeoJson format. We provide a dedicated ImJoy plugin to generate these. Annotations from FIJI . Using annotations in other formats is in principle possible but will require the implementation of dedicated wrappers.","title":"Image annotation"},{"location":"mask-generation/#annotations-in-geojson-with-imjoy","text":"ImJoy provides a dedicated plugin to perform annotations","title":"Annotations in GeoJson with ImJoy"},{"location":"mask-generation/#annotations-with-fiji","text":"FIJI allows to annotate images, and save the annotations into a separate file. Open FIJI Open the ROI manager : Analyze > Tools > ROI manager Open image that you will annotate. Select the annotation tool of choice, e.g. freehand or polygon. Outline first structure of interest. When done, press Add(t) in ROI manager to add outline. Proceed with all other structures. Enabling \"Show all\", will show all defined regions. Save regions by highlighting all regions in the list and pressing on More > Save ... If only one region is saved, this will created a file with the extension .roi . If multiple annotations are saved this will create a .zip file. As a file-name choose the name of the annotated image, followed by a suffix such as _RoiSet.zip . If you have different structures (e.g. nuclei and cells), choose the suffix accordingly, e.g. _cells_RoiSet.zip and _nuclei_RoiSet.zip . IMPORTANT : all structures, e.g. nuclei, have to be annotated. Unwanted elements, e.g. nuclei touching the cell border, can be removed in a post-processing step.","title":"Annotations with FIJI"},{"location":"mask-generation/#convert-annotations-to-images","text":"Once you have annotated the images, you have to convert these annotations to images which can be used as an input for the A-net. We provide a dedicated ImJoy plugin to perform this task. This plugin has different tags , which render the plugin for a given segmentation tasks. You only have to specify a few key properties of your data. The screenshot shown below shows the plugin interface for the segmentation of the cell membrane in the example data. Note that here is only one channel. For the example above, you have to specify Unique identifier for each channel (here there is only one channel with the identifier C3- ) File extension of your images ( .tif in this case) File extension of the annotations (FIJI annotations with _RoiSet.zip ) Once you specified these parameters you can convert an entire folder with annotations by pressing on the plugin itself (the blue text AnnotationImporter ). You will be asked to specify the parent folder containing the different data-sets. The plugin will open all annotation files, create the necessary mask images, and save them together with the corresponding images in a new folder unet_data in the processed folder. It contains two subfolders train and valid . Here, a dedicated folder with the name of the image is created. The actual images are then named with the channel identifier (e.g. cells ) and the image masks with the channel identifier followed by the mask type (e.g. cell_mask_edge.png ). . \u251c\u2500 anet/ \u2502 \u251c\u2500 train/ \u2502 \u2502 \u251c\u2500 C3-img4 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img5 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u2502 \u251c\u2500 valid/ \u2502 \u2502 \u251c\u2500 C3-img1 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 \u251c\u2500 C3-img2 \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 mask_edge.png \u2502 \u2502 ... \u251c\u2500 test/ \u2502 ... \u251c\u2500 train/ \u2502 ... \u251c\u2500 valid/ \u2502 ... This directory can be used as an input directory for the training. NEEDED? It will also create a .zip file that can be easily distributed.","title":"Convert annotations to images"},{"location":"mask-generation/#defining-a-root-folder","text":"By default, ImJoy will open files in your home folder. If your data is at a different location, you can set a root folder. Each time you specify a file, ImJoy will open the file-dialog in this root folder. Press the button Root folder and specify the desired folder. The specified root folder is also saved, and will be resused the next time you launch ImJoy.","title":"Defining a root folder"},{"location":"projection/","text":"3D images: 2D projections \u00b6 Image segmentation is performed in 2D. 3D images thus have to transformed into 2D images with a projection along Z. We provide a plugin to perform such projections, where we provide different approaches. The easiest method to achieve is the so-called maximum intensity projection (MIP) , where for each XY position the highest pixel value along the z-axis is used.","title":"Projection"},{"location":"projection/#3d-images-2d-projections","text":"Image segmentation is performed in 2D. 3D images thus have to transformed into 2D images with a projection along Z. We provide a plugin to perform such projections, where we provide different approaches. The easiest method to achieve is the so-called maximum intensity projection (MIP) , where for each XY position the highest pixel value along the z-axis is used.","title":"3D images: 2D projections"},{"location":"release-notes/","text":"Release Notes \u00b6 Upgrading \u00b6 Maintenance team \u00b6 The current and past team members. @oeway @muellerflorian Version \u00b6 Initial release","title":"Release Notes"},{"location":"release-notes/#release-notes","text":"","title":"Release Notes"},{"location":"release-notes/#upgrading","text":"","title":"Upgrading"},{"location":"release-notes/#maintenance-team","text":"The current and past team members. @oeway @muellerflorian","title":"Maintenance team"},{"location":"release-notes/#version","text":"Initial release","title":"Version"},{"location":"workflows/","text":"Workflows \u00b6 For each workflow, we provide an installation link for ImJoy to generate a dedicated workspace with all necessary plugin, and the possibility to load a pre-trained model. This model can then be applied to test data to familiarize yourself with our approach. The pre-trained model can also be used to initialize training on your own data. This process (also called transfer learning ) tends to reduce the time for training considerably, For each workflow we provide a link to example data. These folders contain Data with the annotations (folders train , valid ), and some test data (folder test ). These folders can be processed with the AnnotationGenerator plugin. Processed data with the annotations being converted to images (folder unet_data ). This folder can be used with the Anet-Lite plugin. The folder structure for the segmentation of the cell membrane looks like This . \u251c\u2500 anet/ # Folder for Anet plugin \u2502 \u251c\u2500 train \u2502 \u2502 \u251c\u2500 img1/ \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 cells_mask_edge.png \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500 valid \u2502 \u2502 \u251c\u2500 img10/ \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 cells_mask_edge.png \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500 test1 \u2502 \u2502 \u251c\u2500 C3-img21.tif \u2502 \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 test/ # Folder for AnnotationGenerator \u2502 \u251c\u2500 C3-img20.tif \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 train/ # Folder for AnnotationGenerator \u2502 \u251c\u2500 C3-img1.tif \u2502 \u251c\u2500 C3-img1__RoiSet.tif \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 valid/ # Folder for AnnotationGenerator \u2502 \u251c\u2500 C3-img10.tif \u2502 \u251c\u2500 C3-img10__RoiSet.tif \u2502 \u251c\u2500 ... . Segmentation of cell membrane \u00b6 This workflow allows to segment cellular membranes. The provided examples is for cell cortex in the developing drosophila embryo. TODO : SHOW EXAMPLE IMAGE We provide some test data for a segmentation of the on Dropbox . Data consists of a GFP stains of the membranes (e.g. C3-img1.tif ) and the corresponding annotations from FIJI (e.g. C3-img1__RoiSet.zip ) TODO should be provided as a Release. Should we pro AnnotationGenerator: TODO Link for ImJoy Segmentation of cells and nuclei \u00b6 This workflow allows to segment cells and nuclei membranes. The provided examples is for CellMask stain of cells, and a DAPI stain of nuclei. cell cortex in the developing drosophila embryo. TODO : SHOW EXAMPLE IMAGE AnnotationGenerator: TODO Link for ImJoy","title":"Workflows"},{"location":"workflows/#workflows","text":"For each workflow, we provide an installation link for ImJoy to generate a dedicated workspace with all necessary plugin, and the possibility to load a pre-trained model. This model can then be applied to test data to familiarize yourself with our approach. The pre-trained model can also be used to initialize training on your own data. This process (also called transfer learning ) tends to reduce the time for training considerably, For each workflow we provide a link to example data. These folders contain Data with the annotations (folders train , valid ), and some test data (folder test ). These folders can be processed with the AnnotationGenerator plugin. Processed data with the annotations being converted to images (folder unet_data ). This folder can be used with the Anet-Lite plugin. The folder structure for the segmentation of the cell membrane looks like This . \u251c\u2500 anet/ # Folder for Anet plugin \u2502 \u251c\u2500 train \u2502 \u2502 \u251c\u2500 img1/ \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 cells_mask_edge.png \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500 valid \u2502 \u2502 \u251c\u2500 img10/ \u2502 \u2502 \u2502 \u251c\u2500 cells.png \u2502 \u2502 \u2502 \u251c\u2500 cells_mask_edge.png \u2502 \u2502 \u251c\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500 test1 \u2502 \u2502 \u251c\u2500 C3-img21.tif \u2502 \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 test/ # Folder for AnnotationGenerator \u2502 \u251c\u2500 C3-img20.tif \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 train/ # Folder for AnnotationGenerator \u2502 \u251c\u2500 C3-img1.tif \u2502 \u251c\u2500 C3-img1__RoiSet.tif \u2502 \u251c\u2500 ... \u2502 \u251c\u2500 valid/ # Folder for AnnotationGenerator \u2502 \u251c\u2500 C3-img10.tif \u2502 \u251c\u2500 C3-img10__RoiSet.tif \u2502 \u251c\u2500 ... .","title":"Workflows"},{"location":"workflows/#segmentation-of-cell-membrane","text":"This workflow allows to segment cellular membranes. The provided examples is for cell cortex in the developing drosophila embryo. TODO : SHOW EXAMPLE IMAGE We provide some test data for a segmentation of the on Dropbox . Data consists of a GFP stains of the membranes (e.g. C3-img1.tif ) and the corresponding annotations from FIJI (e.g. C3-img1__RoiSet.zip ) TODO should be provided as a Release. Should we pro AnnotationGenerator: TODO Link for ImJoy","title":"Segmentation of cell membrane"},{"location":"workflows/#segmentation-of-cells-and-nuclei","text":"This workflow allows to segment cells and nuclei membranes. The provided examples is for CellMask stain of cells, and a DAPI stain of nuclei. cell cortex in the developing drosophila embryo. TODO : SHOW EXAMPLE IMAGE AnnotationGenerator: TODO Link for ImJoy","title":"Segmentation of cells and nuclei"}]}